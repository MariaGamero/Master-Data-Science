{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de las palabras en un texto de Guns&Roses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Welcome To The Jungle\\n\\nWelcome to the jungle\\nWe've got fun 'n' games\\nWe got everything you want\\nHoney, we know the names\\nWe are the people that can find\\nWhatever you may need\\nIf you got the money, honey,\\nWe got your disease\\n\\n[Chorus:]\\nIn the jungle\\nWelcome to the jungle\\nWatch it bring you to your\\nKnees, knees\\nI wanna watch you bleed\\n\\nWelcome to the jungle\\nWe take it day by day\\nIf you want it you're gonna bleed\\nBut it's the price you pay\\nAnd you're a very sexy girl\\nThat's very hard to please\\nYou can taste the bright lights\\nBut you won't get them for free\\n\\nIn the jungle\\nWelcome to the jungle\\nFeel my, my, my serpentine\\nI, I wanna hear you scream\\n\\nWelcome to the jungle\\nIt gets worse here everyday\\nYa learn ta live like an animal\\nIn the jungle where we play\\nIf you got a hunger for what you see\\nYou'll take it eventually\\nYou can have anything you want\\nBut you better not take it from me\\n\\n[Chorus:]\\nIn the jungle\\nWelcome to the jungle\\nWatch it bring you to your\\nKnees, knees\\nI'm gonna watch you bleed\\n\\nAnd when you're high you never\\nEver want to come down, so down, down, yeah!\\n\\nYou know where you are?\\nYou're in the jungle, baby\\nYou're gonna die\\n\\nIn the jungle\\nWelcome to the jungle\\nWatch it bring you to your\\nKnees, knees\\n\\nIn the jungle\\nWelcome to the jungle\\nFeel my, my, my serpentine\\n\\nIn the jungle\\nWelcome to the jungle\\nWatch it bring you to your\\nKnees, knees\\n\\nIn the jungle\\nWelcome to the jungle\\nWatch it bring you t\\no your...\\n\\nIt's gonna bring you down\\nHa!\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carpeta_nombre=\"data/\"\n",
    "archivo_one=\"lyric_one.txt\"\n",
    "\n",
    "with open(carpeta_nombre+archivo_one,\"r\") as f:\n",
    "    texto=f.read()\n",
    "\n",
    "texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A continuación separamos el texto en palabras, las transformamos en mínusculas. \n",
    "#### Filtramos aquellas palabras que no aportan significado,   _stop words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-10070059277c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'txt' is not defined"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "words=[i for i in txt.lower().split() if i not in stop]\n",
    "print(good_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una vez así, cuál es la frecuencia de dichas palabras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-44c00822a170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfreq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "freq ={}\n",
    "for token in words:\n",
    "    if token in freq:\n",
    "        freq[token]+=1\n",
    "    else:\n",
    "        freq[token]=1\n",
    "\n",
    "pals_frecuentes=sorted(freq.items(), key=lambda kv: kv[1],reverse=True)\n",
    "print(pals_frecuentes[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pero OJO! podemos ver cosas raras. Vemos por ejemplo la palabra \"knees\" que sale repetida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vemos que hay palabras con comas, simbolos de exclamación... y hay que quitarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simbolos=[\"(\",\")\",\",\",\",\",\"?\",\".\",\";\",\"[\",\"]\",\":\",\"!\",\"\\\"\"]\n",
    "for simbolo in simbolos:\n",
    "    texto=texto.replace (simbolo,\" \" + simbolo + \" \")\n",
    "    palabras_lista=texto.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'jungle', 'welcome', 'jungle', \"we've\", 'got', 'fun', \"'n'\", 'games', 'got', 'everything', 'want', 'honey', 'know', 'names', 'people', 'find', 'whatever', 'may', 'need', 'got', 'money', 'honey', 'got', 'disease', 'chorus', 'jungle', 'welcome', 'jungle', 'watch', 'bring', 'knees', 'knees', 'wanna', 'watch', 'bleed', 'welcome', 'jungle', 'take', 'day', 'day', 'want', 'gonna', 'bleed', 'price', 'pay', 'sexy', 'girl', \"that's\", 'hard', 'please', 'taste', 'bright', 'lights', 'get', 'free', 'jungle', 'welcome', 'jungle', 'feel', 'serpentine', 'wanna', 'hear', 'scream', 'welcome', 'jungle', 'gets', 'worse', 'everyday', 'ya', 'learn', 'ta', 'live', 'like', 'animal', 'jungle', 'play', 'got', 'hunger', 'see', 'take', 'eventually', 'anything', 'want', 'better', 'take', 'chorus', 'jungle', 'welcome', 'jungle', 'watch', 'bring', 'knees', 'knees', \"i'm\", 'gonna', 'watch', 'bleed', 'high', 'never', 'ever', 'want', 'come', 'yeah', 'know', 'jungle', 'baby', 'gonna', 'die', 'jungle', 'welcome', 'jungle', 'watch', 'bring', 'knees', 'knees', 'jungle', 'welcome', 'jungle', 'feel', 'serpentine', 'jungle', 'welcome', 'jungle', 'watch', 'bring', 'knees', 'knees', 'jungle', 'welcome', 'jungle', 'watch', 'bring', 'gonna', 'bring', 'ha']\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "new_words=[i for i in palabras_lista if i not in stop]\n",
    "good_words=[i for i in new_words if i not in simbolos]\n",
    "print(good_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora si, ya podemos contar la frecuencia de las palabras\n",
    "### Se puede ver que \"knees\" ya sale bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jungle', 20), ('welcome', 11), ('knees', 8), ('watch', 7), ('bring', 6), ('got', 5), ('want', 4), ('gonna', 4), ('bleed', 3), ('take', 3), ('honey', 2), ('know', 2), ('chorus', 2), ('wanna', 2), ('day', 2), ('feel', 2), ('serpentine', 2), (\"we've\", 1), ('fun', 1), (\"'n'\", 1), ('games', 1), ('everything', 1), ('names', 1), ('people', 1), ('find', 1), ('whatever', 1), ('may', 1), ('need', 1), ('money', 1), ('disease', 1)]\n"
     ]
    }
   ],
   "source": [
    "freq ={}\n",
    "for token in good_words:\n",
    "    if token in freq:\n",
    "        freq[token]+=1\n",
    "    else:\n",
    "        freq[token]=1\n",
    "\n",
    "pals_frecuentes=sorted(freq.items(), key=lambda kv: kv[1],reverse=True)\n",
    "print(pals_frecuentes[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como se podía haber hecho esto más rápido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos el texto por \"tokens\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokens = word_tokenize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jungle', 20), ('welcome', 11), ('knees', 8), ('watch', 7), ('bring', 6), ('na', 6), ('got', 5), (\"'re\", 5), ('want', 4), ('gon', 4), ('bleed', 3), ('take', 3), (\"'s\", 3), ('honey', 2), ('know', 2), ('chorus', 2), ('wan', 2), ('day', 2), ('feel', 2), ('serpentine', 2)]\n"
     ]
    }
   ],
   "source": [
    "#filtramos por palabras\n",
    "simbolos=[\"(\",\")\",\",\",\",\",\"?\",\".\",\";\",\"[\",\"]\",\":\",\"!\",\"\\\"\"]\n",
    "words=[i for i in word_tokens if i not in simbolos]\n",
    "\n",
    "#las ponemos todas minúsculas\n",
    "lower_words=[word.lower() for word in words]\n",
    "\n",
    "#por último eliminamos aquellas palabras que no aportan valos al texto y son muy genéricas\n",
    "stop = set(stopwords.words('english'))\n",
    "good_words=[i for i in lower_words if i not in stop]\n",
    "\n",
    "#Una vez aquí, calculamos la frecuencia de las palabras\n",
    "freq ={}\n",
    "for token in good_words:\n",
    "    if token in freq:\n",
    "        freq[token]+=1\n",
    "    else:\n",
    "        freq[token]=1\n",
    "\n",
    "pals_frecuentes=sorted(freq.items(), key=lambda kv: kv[1],reverse=True)\n",
    "print(pals_frecuentes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
